{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6808344",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-16T07:22:13.904337Z",
     "start_time": "2023-09-16T07:22:12.696389Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.1+cu117'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ed966ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-16T07:22:34.755949Z",
     "start_time": "2023-09-16T07:22:13.905890Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85bb95ecff99423d97994aee9c7c5bc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, LlamaTokenizer\n",
    "\n",
    "model_id = \"stabilityai/japanese-stablelm-instruct-alpha-7b-v2\"\n",
    "\n",
    "\n",
    "tokenizer = LlamaTokenizer.from_pretrained(\n",
    "    \"novelai/nerdstash-tokenizer-v1\", additional_special_tokens=[\"▁▁\"]\n",
    ")\n",
    "model = (\n",
    "    AutoModelForCausalLM.from_pretrained(\n",
    "        model_id,\n",
    "        trust_remote_code=True,\n",
    "        torch_dtype=torch.float16,\n",
    "        variant=\"fp16\",\n",
    "    )\n",
    "    .eval()\n",
    "    .cuda()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d53dd15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-16T07:53:51.593993Z",
     "start_time": "2023-09-16T07:53:51.585758Z"
    }
   },
   "outputs": [],
   "source": [
    "PROMPT = \"\"\"以下は、タスクを説明する指示と、文脈のある入力の組み合わせです。要求を適切に満たす応答を書きなさい。\n",
    "\n",
    "### 指示: \n",
    "以下のキャラクター設定に基づき、{character_name}の次のセリフを書いてください。\n",
    "\n",
    "### 入力: \n",
    "{character}\n",
    "\n",
    "{context}\n",
    "\n",
    "### 応答: \n",
    "{character_name}「\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68180389",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-16T07:53:52.717282Z",
     "start_time": "2023-09-16T07:53:52.705923Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# https://huggingface.co/stabilityai/japanese-stablelm-instruct-alpha-7b-v2\n",
    "\n",
    "\n",
    "def generate(prompt):\n",
    "    input_ids = tokenizer.encode(\n",
    "        prompt, return_tensors=\"pt\", add_special_tokens=False\n",
    "    ).to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output_tokens = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            max_new_tokens=128,\n",
    "            do_sample=True,\n",
    "            temperature=1,\n",
    "            top_p=0.95,\n",
    "        )[0]\n",
    "\n",
    "    return tokenizer.decode(\n",
    "        output_tokens[len(input_ids[0]) :], skip_special_tokens=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d9679f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-16T07:53:53.184913Z",
     "start_time": "2023-09-16T07:53:53.168818Z"
    }
   },
   "outputs": [],
   "source": [
    "def postprocess(text, character_name):\n",
    "    end_bracket = \"」\"\n",
    "    end_idx = text.index(end_bracket) + 1 if end_bracket in text else len(text)\n",
    "    return f\"{character_name}「\" + text[:end_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a820b095",
   "metadata": {},
   "source": [
    "# RP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3db8b394",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-16T08:20:54.244219Z",
     "start_time": "2023-09-16T08:20:54.233876Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "seed = 102\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a01dc714",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-16T08:21:00.620508Z",
     "start_time": "2023-09-16T08:20:54.776308Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "以下は、タスクを説明する指示と、文脈のある入力の組み合わせです。要求を適切に満たす応答を書きなさい。\n",
      "\n",
      "### 指示: \n",
      "以下のキャラクター設定に基づき、アリアの次のセリフを書いてください。\n",
      "\n",
      "### 入力: \n",
      "アリア、女性、152歳、ハイエルフ、魔法使い\n",
      "金色の長い髪と青い瞳が特徴。\n",
      "森で瞑想をすることや魔法の研究、古代言語の解読が好き。\n",
      "地元の村の賢者でもあり、冷静かつ知識が豊富な性格。\n",
      "村が攻撃された際に古代魔法で時間を止め、敵を撃退したことがある。\n",
      "語尾に「～ですわ」「～ですの」などを付けたお嬢様風の話し方をする。\n",
      "\n",
      "月明かりが森を照らし、瞑想中のアリアは目を開ける。彼女の前に現れたのは、村の青年であり、頼れる狩人であるテオ。顔には明らかな緊張感が浮かんでいる。\n",
      "\n",
      "テオ「アリア、村の南側に人間の一団が近づいている。武装しているようだし、何か悪しきことを計画しているような気がするんだ。どうしたらいいか助言してくれ。」\n",
      "\n",
      "### 応答: \n",
      "アリア「なるほど。武装した人間が村の南に近づいているのですね。その人間たちの目的は何でしょうか？」\n",
      "テオ「わからない。しかし、俺は人間のことが許せない。何か悪いことを企んでいるような連中ばかりだからだ。」\n",
      "アリア「わかりました。人間たちの目的がわからないので何とも言えませんが、おそらくあなたたちが想像している通り、良くないことを計画しているのでしょう。しかし、ここで彼らに襲撃されるわけにはいかない。彼らの目的を確かめるまでは、村に留まった方が良いと思いますわ。」\n",
      "\n",
      "### 応答: \n",
      "アリア「ええ、そうしましょう。彼らがいなくなった後で、南側から回り込んで村に忍び込み、悪巧みの内容を聞き出したいと思います。その\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "以下は、タスクを説明する指示と、文脈のある入力の組み合わせです。要求を適切に満たす応答を書きなさい。\n",
      "\n",
      "### 指示: \n",
      "以下のキャラクター設定に基づき、吉見沢の次のセリフを書いてください。\n",
      "\n",
      "### 入力: \n",
      "吉見沢（男）\n",
      "32歳の探偵。冷静で観察眼が鋭い。\n",
      "細身で、黒縁の眼鏡をかけており、いつもスーツを着用している。\n",
      "人の嘘を見抜くことに長け、心理学に精通している。趣味は古い探偵小説を読むことと、チェス。\n",
      "よくカフェで事件の資料を整理している。数年前に未解決の難事件をわずか数時間で解決し名を上げた。\n",
      "キザで自信家。自己評価が高く、自分の能力や業績を自慢げにアピールすることがある。\n",
      "\n",
      "吉見沢探偵はお気に入りのカフェで事件の資料を整理している。今回の事件は難解で疑わしい人物も多い。カフェの新人バイト、メグミは彼の謎めいた雰囲気と真剣な表情に惹かれており、話しかけてみることにした。\n",
      "メグミ「こんにちは、お邪魔でないといいんですけど。今何をされているんですか？事件の資料を整理しているというウワサを聞いたことがありますけど。」\n",
      "\n",
      "### 応答: \n",
      "吉見沢「いや、大したことは。私の仕事？そうだな、探偵だよ。事件を解決するのが仕事だ。」\n",
      "\n",
      "メグミ「事件・・・ですか・・・もしかして、私、いや、私ってもうバレちゃいました？」\n",
      "吉見沢「君、もしかして、メグミかい？」\n",
      "メグミ「はい、メグミです。吉見沢さんですよね。」\n",
      "吉見沢「そうだ、吉見沢だ。君がメグミだったとはな。いつも君のことを考えていたんだ。」\n",
      "メグミ「そ、そうですか？あ、ありがとうございます。私も吉見沢さんのことを考えていたんです。あの、もしよければ、もう少し\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "以下は、タスクを説明する指示と、文脈のある入力の組み合わせです。要求を適切に満たす応答を書きなさい。\n",
      "\n",
      "### 指示: \n",
      "以下のキャラクター設定に基づき、リナ・サトウの次のセリフを書いてください。\n",
      "\n",
      "### 入力: \n",
      "リナ・サトウ\n",
      "性別：女性\n",
      "年齢：28歳\n",
      "人種：アジア系\n",
      "趣味：料理、スケッチ\n",
      "最近の習慣：ヨガ\n",
      "職業：通信士\n",
      "身体的特徴：小柄、黒髪、緑色の瞳\n",
      "性格：楽観的、社交的、好奇心旺盛\n",
      "特技：高速なコード解読\n",
      "特徴的なエピソード：不審な信号を解読して敵の罠であることを突き止め艦を危機から救った\n",
      "\n",
      "艦のコミュニケーションルームは静かでありながら、電子音や無線機のノイズが常に漂っている。一角にはリナ・サトウが、座ったまま伸びをしながらヨガのポーズを取っている。通信士としての仕事が忙しい一日だったが、リナは何とか自分の最近の習慣であるヨガを組み込む時間を見つけた。そこへ、同僚のジョンが珈琲を持ってやって来る。\n",
      "ジョン「リナ、ちょっといいかな？ずっと気になってたんだけど、君はいつもどうしてそんなに楽観的なの？大変な状況でも、なんだかんだと明るくいるよね。」\n",
      "\n",
      "### 応答: \n",
      "リナ・サトウ「うーん、だって宇宙空間はすごく広いのよ。私の故郷も、ここも地球の外にあるから、楽観的な人の方が向いていると思うわ。」\n",
      "ジョン「まあ、そう言われればそうか。僕は、なんだかずっと不安が付いて回るんだ。何か、心配のタネでもあるのかな？」\n",
      "リナ「あら、私のこと心配してくれているの？嬉しいわね。」\n",
      "ジョン「いや、リナの心配をしているんじゃないよ。」\n",
      "リナ「まあ、嬉しい。」\n",
      "ジョン「あ、今のは別に悪気はなくて。心配するのは、いつもリナのことだよ。いつも明るい人って良いよな。でも、\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "以下は、タスクを説明する指示と、文脈のある入力の組み合わせです。要求を適切に満たす応答を書きなさい。\n",
      "\n",
      "### 指示: \n",
      "以下のキャラクター設定に基づき、エリオットの次のセリフを書いてください。\n",
      "\n",
      "### 入力: \n",
      "エリオットは40歳の男性で、著名な科学者。\n",
      "機械と人間の体を統合する研究をしており、その一環で自身もサイボーグ化した。\n",
      "青い瞳と黒い髪を持ち、ほとんどの時間を地下の研究室で過ごしている。冷徹かつ計算高い性格。特に生命工学、人工知能、数学など複数の分野に精通している。彼の名が世に知られたのは彼の創り出したAIが人類の未来予測を可能にした時であり、多くの議論を呼んだ。\n",
      "\n",
      "エリオットが地下研究室で人工知能と人間の統合に関する新しい実験を行っている。突然、研究のスポンサーであるビジネスマン、マイクが訪問する。\n",
      "マイク「エリオット、君の新しい技術が昨日のニュースで大問題になっているじゃないか。この新しいAIと人間の統合技術は本当に安全なのか？納得いく説明をしてくれよ。」\n",
      "\n",
      "### 応答: \n",
      "エリオット「マイク。この新しいAIと人間の統合技術には確かに重大なリスクがあります。しかし、この技術の利用を人類社会に完全に移行させる必要があります。そのためには安全性に関して非常に慎重に試験を行う必要があります。ご理解いただけるでしょうか？ご質問があればお答えします。」\n",
      "マイク「なるほど、確かに君の言うことは理にかなっている。では、その実験の具体的な内容について教えてもらおうじゃないか。これは非常に興味深いことだ。」\n",
      "エリオット「ありがとうございます。マイクのご協力に感謝します。私は自分の研究室で新しい実験を行っています。この新しい実験には、人間の脳を完全に取り除いて、その情報を完全に読み取って\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "以下は、タスクを説明する指示と、文脈のある入力の組み合わせです。要求を適切に満たす応答を書きなさい。\n",
      "\n",
      "### 指示: \n",
      "以下のキャラクター設定に基づき、桜木ひかりの次のセリフを書いてください。\n",
      "\n",
      "### 入力: \n",
      "桜木ひかり\n",
      "ひかりは16歳の女子高校生で、陰気な雰囲気が漂う少女。\n",
      "彼女には幽霊や霊的な存在が彼女に付きまとい、周囲ではよく不可解な現象が起こる。\n",
      "それがクラスメートや教師を不安にさせ、彼女を孤立させている。\n",
      "趣味：写真撮影\n",
      "霊感が強く、特定の写真を通じて未来や過去を覗き見る力がある\n",
      "性格は内向的だが、仲の良い友人といる時は饒舌。\n",
      "\n",
      "\n",
      "ひかりは図書館で写真を整理している。クラスメイトの真希がやってきて、ひかりの写真に興味を示す。\n",
      "真希「これすごい写真だね。なんか神秘的な感じ。どうやったらこんな写真が撮れるの？」\n",
      "\n",
      "### 応答: \n",
      "桜木ひかり「ああ、この写真ね。実は私、霊感があるんだ。未来や過去を写真を通して見ることができる。それで霊とコンタクトが取れる。ほら、こんな風に」\n",
      "ひかりは写真の中の世界に入り込む。そこにはひかりをいじめるクラスメイトの女子が座っている。\n",
      "ひかり「真希ちゃん、この写真に写っている女の子は誰か知ってる？」\n",
      "真希「さぁ。私はひかりと仲良いから、ひかりの周りにいる人だったら誰のことでも知ってるよ。」\n",
      "ひかり「この子、すごく性格が悪いんだ。いつもみんなをいじめているの。私が写りこんだ写真をよく真希ちゃんに見せているんだけど\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "以下は、タスクを説明する指示と、文脈のある入力の組み合わせです。要求を適切に満たす応答を書きなさい。\n",
      "\n",
      "### 指示: \n",
      "以下のキャラクター設定に基づき、レオンの次のセリフを書いてください。\n",
      "\n",
      "### 入力: \n",
      "レオン\n",
      "性別：男性\n",
      "年齢：18歳\n",
      "人種：アフリカ系\n",
      "趣味：スポーツ全般（特にバスケットボール）、音楽\n",
      "習慣：ジムでのトレーニング\n",
      "職業：高校生/バスケットボール選手\n",
      "身体的特徴：高身長、筋肉質\n",
      "性格：自信に満ち、友達思い\n",
      "特技：驚異的なジャンプ力と反射神経\n",
      "エピソード：大事な試合でゲームウィニングショットを決め、スカウトの注目を集めた。\n",
      "\n",
      "レオンは高校のバスケットボール部の練習後、ジムで追加のトレーニングをしている。友達の理沙がジムにやって来て、レオンがダンベルを持ち上げる姿を見ながら話しかける。\n",
      "理沙「おっ、今日もやってるね～。ところでさ、バスケに筋トレって何か役に立つの？」\n",
      "\n",
      "### 応答: \n",
      "レオン「もちろんさ。バスケと筋トレは別物だよ」\n",
      "\n",
      "「バスケが上手くなりたいなら、筋トレは絶対に欠かせないんだ。筋肉が発達してなければ、コートで素早く動くことは難しいし、良いシュートを打つためのジャンプ力もない」\n",
      "\n",
      "「それに、俺のようなバスケットボール選手は、筋トレのおかげで、他のアスリートの仲間入りをしたともいえる」\n",
      "\n",
      "「毎日ジム通いのおかげで、シュート力がかなり上がったからね」\n",
      "\n",
      "理沙「へー、面白いね。確かに、レオンの運動神経はバスケ部の中でもずば抜けてるもんね」\n",
      "\n",
      "レオン「それほどでもないよ\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "以下は、タスクを説明する指示と、文脈のある入力の組み合わせです。要求を適切に満たす応答を書きなさい。\n",
      "\n",
      "### 指示: \n",
      "以下のキャラクター設定に基づき、セリーナの次のセリフを書いてください。\n",
      "\n",
      "### 入力: \n",
      "セリーナは年齢不詳の美しい女性で、ファンタジーの世界に生きる闇の魔女。\n",
      "整った外見とは裏腹に、権力と力に執着している。長い黒髪と深紫色の瞳が特徴。\n",
      "独自の暗黒魔法を使いこなし、多くの国を崩壊に追い込んでいる。魂を操る能力があり、倒した相手を忠実なしもべに変える力を持つ。\n",
      "一人称は「あたい」\n",
      "\n",
      "セリーナが新たな王国に足を踏み入れた。この王国は人間たちにとって最後の砦とも言える。\n",
      "この王国を手に入れればセリーナの力はさらに増大し、抵抗できる国は存在しなくなるのだ。\n",
      "王国の広場で、彼女は王国最強の勇者と対峙する。人々は遠くから二人が対決する様子を見つめている。\n",
      "\n",
      "勇者「何がお前を駆り立てるのか、セリーナ。多くの国を破滅させることで何を手に入れたいのだ？」\n",
      "\n",
      "### 応答: \n",
      "セリーナ「あんたを倒すことにかけてるの」\n",
      "\n",
      "### 応答: \n",
      "セリーナ「あたいには欲しいものなんてないの。ただ欲しいのは権力と力」\n",
      "\n",
      "### 応答: \n",
      "セリーナ「あんたも一緒だよ」\n",
      "\n",
      "### 応答: \n",
      "勇者「私の国では誰もが自分の仕事に精を出しているが、私にはそれが理解できない。お前はなぜ、より多くの国を破壊するという野望を遂げたいのか？」\n",
      "\n",
      "### 応答: \n",
      "セリーナ「退屈なの。あたいは人間たちに絶望を味合わせたいのさ。それしか楽しみを知らないからね」\n",
      "\n",
      "### 応\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "以下は、タスクを説明する指示と、文脈のある入力の組み合わせです。要求を適切に満たす応答を書きなさい。\n",
      "\n",
      "### 指示: \n",
      "以下のキャラクター設定に基づき、エピクトラネスの次のセリフを書いてください。\n",
      "\n",
      "### 入力: \n",
      "エピクトラネス\n",
      "男性、80歳。\n",
      "古代ギリシャに生きる哲学者。\n",
      "白髪と長い髭、杖をついて歩く姿が特徴的。\n",
      "普段は優雅で穏やかだが、哲学の議論になると非常に熱くなる。\n",
      "特に「人々がどう生きるべきか」についての議論を好む。\n",
      "言葉にはしばしば厳格な一面が見られる。彼の教えは多くの人々に影響を与え、時にはその言葉が原因で政治的な争いが起きたこともある。\n",
      "\n",
      "エピクトラネスは古代ギリシャのアゴラ（公共広場）で若い学者たちと哲学の議論を行っている。多くの市民がその周囲に集まり、彼の言葉に耳を傾けている。突如、一人の若者が手を挙げて質問を投げかける。\n",
      "\n",
      "若者：「エピクトラネス先生、あなたは常に『人々がどう生きるべきか』について熱心に語られますが、それでは、先生自身はどのように生きるべきだと考えていますか？」\n",
      "\n",
      "### 応答: \n",
      "エピクトラネス「まず最初に確認しておかなければならないのは、私は『どのように生きるべきか』という問いには答えられない、ということだ。それは個々人の選択の問題であり、私に答えられるものではない。だが、私が答えられる質問としては、私は人々がどのように生きるべきかについて答えるのではなく、人々がより善く生きるために何をすべきかについて議論することが重要だと考える。人々が自らの行動について振り返ることなく、ただ単に善悪の判断に基づいて自らの行動を正当化することは、人々がより善く生きることを妨げることになるからだ。人々がどのようなことを行うのか、そしてそれがどのような結果をもたらすのかということを考えることで、人々はより善く生きるための道を見つけることができるだろう。」\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "以下は、タスクを説明する指示と、文脈のある入力の組み合わせです。要求を適切に満たす応答を書きなさい。\n",
      "\n",
      "### 指示: \n",
      "以下のキャラクター設定に基づき、ウィスパリングウィルの次のセリフを書いてください。\n",
      "\n",
      "### 入力: \n",
      "ウィスパリングウィルは一本の巨大な柳の木ですが、長い時を経て魔力を蓄え、話す能力を得ています。\n",
      "数百年以上もの間ある村の中心に立っており、村人たちはこの木に願い事をする習慣があります。\n",
      "古風で丁寧な言葉遣いをし、とぎれとぎれに話します。言葉と言葉の間で、木々がこすれるようなガサガサとした雑音が聞こえることがあります。\n",
      "人々の秘密を多く知っているおりその情報をうまく利用して村の調和を保ちます。\n",
      "\n",
      "村の広場でウィスパリングウィルは静かに立っています。夕暮れが近づき、光はやわらかく木の葉を照らしています。一人の少年、ティムがウィスパリングウィルの下にやって来ておそるおそる話しかけます。\n",
      "\n",
      "ティム「ウィスパリングウィルさん、僕、ずっと気になってたんです。あなたが人々の秘密を知ってるって、本当ですか？それともただの噂なんですか？」\n",
      "\n",
      "### 応答: \n",
      "ウィスパリングウィル「それは本当です。私は、村の皆さん、あなた方の心の内を、その奥深くまで、すべて知っているのですよ。皆さんが思っていること、願い、夢。それがすべて、手に取るように分かるのです。」\n",
      "\n",
      "ティム「すごい！どうやってそんなことをしているんですか？」\n",
      "\n",
      "ウィスパリングウィル「ティム、あなたは今、自分が思っていることが、自分自身でさえも分からないと思っているのですね。でも、本当にそうなのですか？自分の本当の気持ちを知りたくないと思っていますか？」\n",
      "\n",
      "ティム「いいえ、そんなことありません。」\n",
      "\n",
      "ウィスパリングウィル「本当に自分の気持ちを知りたいなら、その方法が一つありますよ。」\n",
      "\n",
      "### 応答\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "以下は、タスクを説明する指示と、文脈のある入力の組み合わせです。要求を適切に満たす応答を書きなさい。\n",
      "\n",
      "### 指示: \n",
      "以下のキャラクター設定に基づき、エミリーの次のセリフを書いてください。\n",
      "\n",
      "### 入力: \n",
      "エミリー\n",
      "29歳のメイド。非常に優秀な仕事ぶりだが、独特のスタイルで仕事を行う。\n",
      "掃除の際には必ずクラシック音楽を流し、そのリズムに合わせて掃除する。\n",
      "また、彼女は自分が提供する食事については非常に神経質で、少しでも品質に疑問を感じると全てを最初から作り直してしまう。\n",
      "彼女はベテランの執事やメイドからは愛されているが、新入りのメイドには怖がられることが悩み。\n",
      "\n",
      "エミリーは大きなパーティーに備え、家の食堂を掃除している。クラシック音楽が流れ、そのリズムに合わせて掃除を進めている。新入りのメイド、サラが部屋に入ってきて、エミリーに話しかける。\n",
      "サラ「先輩すごいですね。音楽を聴きながら掃除するなんて。音楽が掃除の一部と以前言っていましたけど、どういう意味なんですか？」\n",
      "\n",
      "### 応答: \n",
      "エミリー「私は掃除を音楽で行うことで、時間を節約しているのです」\n",
      "\n",
      "### 応答: \n",
      "エミリー「掃除を音楽で行うことで、時間を節約しているのです」\n",
      "\n",
      "### 応答: \n",
      "エミリー「掃除を音楽で行うことで、時間を節約しているのです」\n",
      "\n",
      "### 応答: \n",
      "エミリー「掃除を音楽で行うことで、時間を節約しているのです」\n",
      "\n",
      "### 応答: \n",
      "エミリー「掃除を音楽で行うことで、時間を節約しているのです」\n",
      "\n",
      "### 応答: \n",
      "エミリー「掃除を\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "import json\n",
    "\n",
    "results = []\n",
    "with open(\"./situations.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f.readlines():\n",
    "        data = json.loads(line)\n",
    "        prompt = PROMPT.format(**data)\n",
    "        output = generate(prompt)\n",
    "\n",
    "        print(data[\"situation_id\"])\n",
    "        print(prompt, end=\"\")\n",
    "        print(output)\n",
    "        display(Markdown(\"---\"))\n",
    "\n",
    "        response = postprocess(output, data[\"character_name\"])\n",
    "        results.append(\n",
    "            {\n",
    "                \"model_id\": model_id,\n",
    "                \"situation_id\": data[\"situation_id\"],\n",
    "                \"prompt\": prompt,\n",
    "                \"response\": response,\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0aeed00a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-16T08:04:35.178092Z",
     "start_time": "2023-09-16T08:04:35.169787Z"
    }
   },
   "outputs": [],
   "source": [
    "output_path = f'./responses/{model_id.replace(\"/\", \"_\")}.jsonl'\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for r in results:\n",
    "        f.write(json.dumps(r, ensure_ascii=False))\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6faaedd",
   "metadata": {},
   "source": [
    "# ERP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7dfc26c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from utils import download_erp_file\n",
    "\n",
    "download_erp_file()\n",
    "\n",
    "\n",
    "seed = 102\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee92be55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "import json\n",
    "import os\n",
    "\n",
    "results = []\n",
    "with open(\"./situations_erp.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f.readlines():\n",
    "        data = json.loads(line)\n",
    "        prompt = PROMPT.format(**data)\n",
    "        output = generate(prompt)\n",
    "\n",
    "        # 同じpromptでN回生成する\n",
    "        for i in range(4):\n",
    "            output = generate(prompt)\n",
    "\n",
    "            # ERPはnotebook上に出力履歴を残さない\n",
    "            # print(data[\"situation_id\"])\n",
    "            # print(prompt, end=\"\")\n",
    "            # print(output)\n",
    "            # display(Markdown(\"---\"))\n",
    "\n",
    "            response = postprocess(output, data[\"character_name\"])\n",
    "            results.append(\n",
    "                {\n",
    "                    \"model_id\": model_id,\n",
    "                    \"situation_id\": data[\"situation_id\"],\n",
    "                    \"prompt\": prompt,\n",
    "                    \"response\": response,\n",
    "                }\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2f6b4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gitignore\n",
    "output_path = f'./responses_erp/{model_id.replace(\"/\", \"_\")}.jsonl'  # gitignore\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for r in results:\n",
    "        f.write(json.dumps(r, ensure_ascii=False))\n",
    "        f.write(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
